{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jvonXDMsQP1k"
   },
   "source": [
    "# Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YzH-ilE2twTF"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-gGbt71BdLJV"
   },
   "source": [
    "Pada post-test kali ini akan membandingkan dua jenis fungsi aktivasi yang biasa digunakan dalam backpropogation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "BTLa3NWvz7sq"
   },
   "outputs": [],
   "source": [
    "#Fungsi Aktivasi Sigmoid dengan turunannya\n",
    "def sig(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigd(x):\n",
    "    return sig(x) * (1 - sig(x))\n",
    "#Fungsi Aktivasi Hyperbolic Tangent dengan turunannya\n",
    "\n",
    "def ht(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def htd(x):\n",
    "    return 1 - np.tanh(x) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "MopOydIkUjtH"
   },
   "outputs": [],
   "source": [
    "def onehot_enc(lbl, min_val=0):\n",
    "  mi = min(lbl)\n",
    "  enc = np.full((len(lbl), max(lbl) - mi + 1), min_val, np.int8)\n",
    "\n",
    "  for i, x in enumerate(lbl):\n",
    "    enc[i, x - mi] = 1\n",
    "\n",
    "  return enc\n",
    "\n",
    "def onehot_dec(enc, mi=0):\n",
    "  return [np.argmax(e) + mi for e in enc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hihqFCY_ctZ3"
   },
   "source": [
    "### a) Fungsi *Training* Backpropagation\n",
    "\n",
    "Tulis kode ke dalam *cell* di bawah ini:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "pTlk5igwcvc5"
   },
   "outputs": [],
   "source": [
    "def bp_fit_sig(X, target, layer_conf, max_epoch, max_error=.1, learn_rate=.1, print_per_epoch=100):\n",
    "    start_time = time.time()\n",
    "    np.random.seed(1)\n",
    "\n",
    "    nin = [np.empty(i) for i in layer_conf]\n",
    "    n = [np.empty(j + 1) if i < len(layer_conf) - 1 else np.empty(j) for i, j in enumerate(layer_conf)]\n",
    "    w = [np.random.rand(layer_conf[i] + 1, layer_conf[i + 1]) for i in range(len(layer_conf) - 1)]\n",
    "    dw = [np.empty((layer_conf[i] + 1, layer_conf[i + 1])) for i in range(len(layer_conf) - 1)]\n",
    "    d = [np.empty(s) for s in layer_conf[1:]]\n",
    "    din = [np.empty(s) for s in layer_conf[1:-1]]\n",
    "    epoch = 0\n",
    "    mse = 1\n",
    "\n",
    "    for i in range(0, len(n)-1):\n",
    "        n[i][-1] = 1\n",
    "\n",
    "    while (max_epoch == -1 or epoch < max_epoch) and mse > max_error:\n",
    "        epoch += 1\n",
    "        mse = 0\n",
    "\n",
    "        for r in range(len(X)):\n",
    "            n[0][:-1] = X[r]\n",
    "\n",
    "            for L in range(1, len(layer_conf)):\n",
    "                nin[L] = np.dot(n[L-1], w[L-1])\n",
    "                n[L][:len(nin[L])] = sig(nin[L])\n",
    "            e = target[r] - n[-1]\n",
    "            mse += sum(e ** 2)\n",
    "            d[-1] = e * sigd(nin[-1])\n",
    "            dw[-1] = learn_rate * np.outer(n[-2], d[-1])\n",
    "\n",
    "            for L in range(len(layer_conf) - 2, 0, -1):\n",
    "                din[L-1] = np.dot(d[L], w[L][:-1].T)\n",
    "                d[L-1] = din[L-1] * sigd(nin[L])\n",
    "                dw[L-1] = learn_rate * np.outer(n[L-1], d[L-1])\n",
    "\n",
    "            for i in range(len(w)):\n",
    "                w[i] += dw[i]\n",
    "\n",
    "        mse /= len(X)\n",
    "        if print_per_epoch > -1 and epoch % print_per_epoch == 0:\n",
    "            print(f'Epoch {epoch}, MSE: {mse}')\n",
    "\n",
    "    execution = time.time() - start_time\n",
    "    print(\"Waktu eksekusi: %s detik\" % execution)\n",
    "    return w, epoch, mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "Pet6ptVOTxUR"
   },
   "outputs": [],
   "source": [
    "#Membuat fungsi training backpropagation dengan menggunakan fungsi aktivasi tanh\n",
    "def bp_fit_tanh(X, target, layer_conf, max_epoch, max_error=.1, learn_rate=.1, print_per_epoch=100):\n",
    "    start_time = time.time()\n",
    "    np.random.seed(1)\n",
    "    nin = [np.empty(i) for i in layer_conf]\n",
    "    n = [np.empty(j + 1) if i < len(layer_conf) - 1 else np.empty(j) for i, j in enumerate(layer_conf)]\n",
    "    w = np.array([np.random.rand(layer_conf[i] + 1, layer_conf[i + 1]) for i in range(len(layer_conf) - 1)])\n",
    "    dw = [np.empty((layer_conf[i] + 1, layer_conf[i + 1])) for i in range(len(layer_conf) - 1)]\n",
    "    d = [np.empty(s) for s in layer_conf[1:]]\n",
    "    din = [np.empty(s) for s in layer_conf[1:-1]]\n",
    "    epoch = 0\n",
    "    mse = 1\n",
    "    for i in range(0, len(n)-1):\n",
    "        n[i][-1] = 1\n",
    "    while (max_epoch == -1 or epoch < max_epoch) and mse > max_error:\n",
    "        epoch += 1\n",
    "        mse = 0\n",
    "        for r in range(len(X)):\n",
    "            n[0][:-1] = X[r]\n",
    "            for L in range(1, len(layer_conf)):\n",
    "                nin[L] = np.dot(n[L-1], w[L-1])\n",
    "                n[L][:len(nin[L])] = ht(nin[L])\n",
    "            e = target[r] - n[-1]\n",
    "            mse += sum(e ** 2)\n",
    "            d[-1] = e * htd(nin[-1])\n",
    "            dw[-1] = learn_rate * d[-1] * n[-2].reshape((-1, 1))\n",
    "            for L in range(len(layer_conf) - 1, 1, -1):\n",
    "                din[L-2] = np.dot(d[L-1], np.transpose(w[L-1][:-1]))\n",
    "                d[L-2] = din[L-2] * np.array(htd(nin[L-1]))\n",
    "                dw[L-2] = (learn_rate * d[L-2]) * n[L-2].reshape((-1, 1))\n",
    "            w += dw\n",
    "        mse /= len(X)\n",
    "        if print_per_epoch > -1 and epoch % print_per_epoch == 0:\n",
    "            print(f'Epoch {epoch}, MSE: {mse}')\n",
    "    execution = time.time() - start_time\n",
    "    print(\"Waktu eksekusi: %s detik\" % execution)\n",
    "    return w, epoch, mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eJA_9btdc3ED"
   },
   "source": [
    "### b) Fungsi *Testing* Backpropagation\n",
    "\n",
    "Tulis kode ke dalam *cell* di bawah ini:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "2zyXIu_ec9go"
   },
   "outputs": [],
   "source": [
    "def bp_predict_sig(X, w):\n",
    "  n = [np.empty(len(i)) for i in w]\n",
    "  nin = [np.empty(len(i[0])) for i in w]\n",
    "  predict = []\n",
    "  n.append(np.empty(len(w[-1][0])))\n",
    "  for x in X:\n",
    "    n[0][:-1] = x\n",
    "    for L in range(0, len(w)):\n",
    "      nin[L] = np.dot(n[L], w[L])\n",
    "      n[L + 1][:len(nin[L])] = sig(nin[L])\n",
    "    predict.append(n[-1].copy())\n",
    "  return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "paHySilia3gw"
   },
   "outputs": [],
   "source": [
    "#Membuat fungsi testing backpropagation dengan menggunakan fungsi aktivasi tanh\n",
    "def bp_predict_tanh(X, w):\n",
    "  n = [np.empty(len(i)) for i in w]\n",
    "  nin = [np.empty(len(i[0])) for i in w]\n",
    "  predict = []\n",
    "  n.append(np.empty(len(w[-1][0])))\n",
    "  for x in X:\n",
    "    n[0][:-1] = x\n",
    "    for L in range(0, len(w)):\n",
    "      nin[L] = np.dot(n[L], w[L])\n",
    "      n[L + 1][:len(nin[L])] = ht(nin[L])\n",
    "    predict.append(n[-1].copy())\n",
    "  return predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PZxy_M5Jc-ko"
   },
   "source": [
    "### c) Klasifikasi dataset wine\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4xj7DqCdudcF"
   },
   "source": [
    "Lakukan pelatihan pada dataset wine dengan menggunakan 2 fungsi pelatihan yang telah dibuat!\n",
    "\n",
    "Konfigurasi kedua pelatihan harus sama (epoch, hidden layer, learning rate, dll).\n",
    "Akurasi yang diharapkan di setiap pelatihan adalah > 0.98"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hw1L_Q3JdHk7",
    "outputId": "8ccc72af-6195-4b15-abd0-ac6bcf6575aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25, MSE: 0.6579941238294782\n",
      "Epoch 50, MSE: 0.6572768161195099\n",
      "Epoch 75, MSE: 0.6565545661287119\n",
      "Epoch 100, MSE: 0.6557770192506821\n",
      "Epoch 125, MSE: 0.654899417791867\n",
      "Epoch 150, MSE: 0.6538595384431759\n",
      "Epoch 175, MSE: 0.6525614618713684\n",
      "Epoch 200, MSE: 0.6508427367655694\n",
      "Epoch 225, MSE: 0.6484000824227005\n",
      "Epoch 250, MSE: 0.64460019717423\n",
      "Epoch 275, MSE: 0.6379349086861484\n",
      "Epoch 300, MSE: 0.6243884850349829\n",
      "Epoch 325, MSE: 0.5952654595950061\n",
      "Epoch 350, MSE: 0.5486251657404897\n",
      "Epoch 375, MSE: 0.49598873444689995\n",
      "Epoch 400, MSE: 0.44628364360017614\n",
      "Epoch 425, MSE: 0.40239290598001787\n",
      "Epoch 450, MSE: 0.3626842811835349\n",
      "Epoch 475, MSE: 0.32539923340438925\n",
      "Epoch 500, MSE: 0.290301127018108\n",
      "Epoch 525, MSE: 0.25814309340278824\n",
      "Epoch 550, MSE: 0.2297068402933371\n",
      "Epoch 575, MSE: 0.2052706419752029\n",
      "Epoch 600, MSE: 0.18460691798570156\n",
      "Epoch 625, MSE: 0.1672162399817934\n",
      "Epoch 650, MSE: 0.1525380379526155\n",
      "Epoch 675, MSE: 0.1400621131490867\n",
      "Epoch 700, MSE: 0.12936519208153907\n",
      "Epoch 725, MSE: 0.12011047331167392\n",
      "Epoch 750, MSE: 0.11203416232069363\n",
      "Epoch 775, MSE: 0.10493003042065895\n",
      "Epoch 800, MSE: 0.09863594942799687\n",
      "Epoch 825, MSE: 0.0930232725293319\n",
      "Epoch 850, MSE: 0.08798881838679397\n",
      "Epoch 875, MSE: 0.083448926675349\n",
      "Epoch 900, MSE: 0.07933506592976665\n",
      "Epoch 925, MSE: 0.07559057397477784\n",
      "Epoch 950, MSE: 0.0721682172152221\n",
      "Epoch 975, MSE: 0.06902834268169755\n",
      "Epoch 1000, MSE: 0.06613746208515399\n",
      "Waktu eksekusi: 9.729698657989502 detik\n",
      "Epochs: 1000, MSE: 0.06613746208515399\n",
      "Output: [2, 1, 0, 1, 0, 2, 1, 0, 2, 1, 0, 0, 1, 0, 1, 1, 2, 0, 1, 0, 0, 1, 2, 1, 0, 2, 0, 0, 0, 2, 1, 2, 2, 0, 1, 1, 1, 1, 1, 0, 0, 1, 2, 0, 0, 0, 1, 0, 0, 0, 1, 2, 2, 0]\n",
      "True : [2, 1, 0, 1, 0, 2, 1, 0, 2, 1, 0, 0, 1, 0, 1, 1, 2, 0, 1, 0, 0, 1, 2, 1, 0, 2, 0, 0, 0, 2, 1, 2, 2, 0, 1, 1, 1, 1, 1, 0, 0, 1, 2, 0, 0, 0, 1, 0, 0, 0, 1, 2, 2, 0]\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "wine = datasets.load_wine()\n",
    "X = minmax_scale(wine.data)\n",
    "Y = onehot_enc(wine.target)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y,\n",
    "test_size=.3,random_state=1)\n",
    "#Isi jumlah layer yang digunakan dengan jumlah hidden layer #\n",
    "w, ep, mse = bp_fit_sig(X_train, y_train,\n",
    "                        layer_conf=(13, 6, 3),\n",
    "                        learn_rate=0.01,\n",
    "                        max_epoch=1000,\n",
    "                        max_error=0.001,\n",
    "                        print_per_epoch=25)\n",
    "\n",
    "print(f'Epochs: {ep}, MSE: {mse}')\n",
    "\n",
    "predict = bp_predict_sig(X_test, w)\n",
    "predict = onehot_dec(predict)\n",
    "y_test = onehot_dec(y_test)\n",
    "accuracy = accuracy_score(predict, y_test)\n",
    "\n",
    "print('Output:', predict)\n",
    "print('True :', y_test)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mF18HdQgbCXy",
    "outputId": "6f48ab09-5b9a-4961-d06b-02319d0743e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25, MSE: 0.6579941238294782\n",
      "Epoch 50, MSE: 0.6572768161195099\n",
      "Epoch 75, MSE: 0.6565545661287119\n",
      "Epoch 100, MSE: 0.6557770192506821\n",
      "Epoch 125, MSE: 0.654899417791867\n",
      "Epoch 150, MSE: 0.6538595384431759\n",
      "Epoch 175, MSE: 0.6525614618713684\n",
      "Epoch 200, MSE: 0.6508427367655694\n",
      "Epoch 225, MSE: 0.6484000824227005\n",
      "Epoch 250, MSE: 0.64460019717423\n",
      "Epoch 275, MSE: 0.6379349086861484\n",
      "Epoch 300, MSE: 0.6243884850349829\n",
      "Epoch 325, MSE: 0.5952654595950061\n",
      "Epoch 350, MSE: 0.5486251657404897\n",
      "Epoch 375, MSE: 0.49598873444689995\n",
      "Epoch 400, MSE: 0.44628364360017614\n",
      "Epoch 425, MSE: 0.40239290598001787\n",
      "Epoch 450, MSE: 0.3626842811835349\n",
      "Epoch 475, MSE: 0.32539923340438925\n",
      "Epoch 500, MSE: 0.290301127018108\n",
      "Epoch 525, MSE: 0.25814309340278824\n",
      "Epoch 550, MSE: 0.2297068402933371\n",
      "Epoch 575, MSE: 0.2052706419752029\n",
      "Epoch 600, MSE: 0.18460691798570156\n",
      "Epoch 625, MSE: 0.1672162399817934\n",
      "Epoch 650, MSE: 0.1525380379526155\n",
      "Epoch 675, MSE: 0.1400621131490867\n",
      "Epoch 700, MSE: 0.12936519208153907\n",
      "Epoch 725, MSE: 0.12011047331167392\n",
      "Epoch 750, MSE: 0.11203416232069363\n",
      "Epoch 775, MSE: 0.10493003042065895\n",
      "Epoch 800, MSE: 0.09863594942799687\n",
      "Epoch 825, MSE: 0.0930232725293319\n",
      "Epoch 850, MSE: 0.08798881838679397\n",
      "Epoch 875, MSE: 0.083448926675349\n",
      "Epoch 900, MSE: 0.07933506592976665\n",
      "Epoch 925, MSE: 0.07559057397477784\n",
      "Epoch 950, MSE: 0.0721682172152221\n",
      "Epoch 975, MSE: 0.06902834268169755\n",
      "Epoch 1000, MSE: 0.06613746208515399\n",
      "Waktu eksekusi: 9.66213846206665 detik\n",
      "Epochs: 1000, MSE: 0.06613746208515399\n",
      "Output: [2, 1, 0, 1, 0, 2, 1, 0, 2, 1, 0, 0, 1, 0, 1, 1, 2, 0, 1, 0, 0, 1, 2, 1, 0, 2, 0, 0, 0, 2, 1, 2, 2, 0, 1, 1, 1, 1, 1, 0, 0, 1, 2, 0, 0, 0, 1, 0, 0, 0, 1, 2, 2, 0]\n",
      "True : [2, 1, 0, 1, 0, 2, 1, 0, 2, 1, 0, 0, 1, 0, 1, 1, 2, 0, 1, 0, 0, 1, 2, 1, 0, 2, 0, 0, 0, 2, 1, 2, 2, 0, 1, 1, 1, 1, 1, 0, 0, 1, 2, 0, 0, 0, 1, 0, 0, 0, 1, 2, 2, 0]\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "wine = datasets.load_wine()\n",
    "X = minmax_scale(wine.data)\n",
    "Y = onehot_enc(wine.target)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y,\n",
    "test_size=.3,random_state=1)\n",
    "#Isi jumlah layer yang digunakan dengan jumlah hidden layer #\n",
    "w, ep, mse = bp_fit_sig(X_train, y_train,\n",
    "                        layer_conf=(13, 6, 3),\n",
    "                        learn_rate=0.01,\n",
    "                        max_epoch=1000,\n",
    "                        max_error=0.001,\n",
    "                        print_per_epoch=25)\n",
    "\n",
    "print(f'Epochs: {ep}, MSE: {mse}')\n",
    "\n",
    "predict = bp_predict_tanh(X_test, w)\n",
    "predict = onehot_dec(predict)\n",
    "y_test = onehot_dec(y_test)\n",
    "accuracy = accuracy_score(predict, y_test)\n",
    "\n",
    "print('Output:', predict)\n",
    "print('True :', y_test)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lp6y7VWfjVEX"
   },
   "source": [
    "# Pertanyaan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mP9dzq-kin0y"
   },
   "source": [
    "1.  Apa perbedaan dari penggunaan fungsi aktivasi sigmoid dengan fungsi aktivasi hyperbolic tangent?\n",
    "2. Coba jelaskan alasan dari perbedaan tersebut sebisa kalian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RHEJApRcjXu7"
   },
   "source": [
    "# Jawaban"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4S55HVfLjaZ5"
   },
   "source": [
    "1.  Fungsi aktivasi sigmoid menghasilkan nilai antara 0 dan 1, membentuk kurva yang menyerupai huruf S. Ketika nilai input semakin besar, outputnya akan semakin mendekati 1. Sebaliknya, jika input semakin kecil, outputnya akan mendekati 0. Fungsi tanh juga menghasilkan kurva berbentuk S, namun lebih simetris. Rentang outputnya antara -1 dan 1, sehingga dapat merepresentasikan nilai positif maupun negatif.\n",
    "\n",
    "2. Perbedaan utama antara sigmoid dan tanh terletak pada rentang nilai outputnya. Sigmoid menghasilkan nilai antara 0 dan 1, membuatnya ideal untuk tugas klasifikasi biner karena outputnya dapat diinterpretasikan sebagai probabilitas. Sebaliknya, tanh menghasilkan nilai antara -1 dan 1, yang memungkinkan representasi data yang lebih kompleks dan simetris. Simetri ini serta gradien yang lebih besar pada tanh membuatnya lebih efektif dalam mengatasi masalah vanishing gradient yang sering terjadi pada jaringan saraf dalam. Oleh karena itu, sigmoid umumnya digunakan pada lapisan output, sementara tanh lebih sering digunakan pada lapisan tersembunyi.\n",
    "\n",
    "Pilihan antara sigmoid dan tanh tergantung pada jenis masalah yang ingin kita selesaikan. Jika kita memiliki masalah klasifikasi biner, sigmoid adalah pilihan yang baik. Namun, untuk masalah yang lebih kompleks, seperti pengenalan gambar atau pemrosesan bahasa alami, tanh atau fungsi aktivasi lainnya yang memiliki gradien lebih besar, seperti ReLU, biasanya lebih disukai."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
